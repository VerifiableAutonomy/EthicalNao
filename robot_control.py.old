#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 14 13:57:06 2017

@author: paul
"""
#import time
#import inspect
#import shutil
#import os
#import sys
#import scipy.io as io
#import matplotlib.pyplot as pyplot
import numpy
#import warnings
import threading
#import Queue
import multiprocessing as mp
#from library import HTMLlog
from library import Utilities
from library import Vicon
from library import Robot
from library import PathPlanning
#from library import easygui
from library import Consequence_para


#==============================================================================
# Runs the CE. CE logs data of the perceived human world view, the simulations of different consequences
# Needs to maintain a model of the human's view of the world for use in planning and assessing consequences, i.e., update the models held by the CE according to 'sensor' data. 
# CE can compare human actions with predicted path for different possible world models to help in assessing plan.
#==============================================================================

#init function
#needs a handle to the tracker
#needs the logging filename root string - includes the dierctory to log to
#needs the settings file identifier
#array of possible human world views with confidence values. Each world view is a list of the co-ordinates of each object and their danger scores as perceived by the human (can make these discrete to start with, e.g., obstacle, danger)
#the array of human views will need to be initialised based on the robots perception of the world at experiment start (from settings file + tracker information), the values could initially just come from the settings file
#the array of human views will need to be updated as the experiment progresses
#robot object to allow sending of commands to the robot
#CE instance

class robot_controller():
    def __init__(self, tracker, robot_q, human_q, session_path, settings, ip_robot = '192.168.20.224'):
        self.tracker = tracker
        self.log_file = session_path
        self.robot = Robot.Robot(ip_robot, 'ROBOT', self.tracker)
        self.robot_q = robot_q #Queue.Queue created in main thread that allows robot to pass messages
        self.human_q = human_q #list of Queue.Queues created in main thread that allows robot to get messages from human(s)
        self.ack = threading.Event()
        self.settings = settings
         
   

        self.Experiment_Logger = Utilities.Logger('ROBOT_control')
        self.Experiment_Logger.write('Generating robot objects')
        plan_types = ['move','warn','point']
        self.robot_graph = {}
        self.CE = {}
        for plan in plan_types:
            self.robot_graph[plan] = PathPlanning.Planner(self.tracker)#one graph for each plan type
            self.CE[plan] = Consequence_para.ConsequenceEngine('ROBOT', self.settings['humans'], self.tracker, plan, self.settings, engine_name='CEngine_'+plan)#human_names ['HUMAN_A','HUMAN_B']
            if 'self_obstacles' in self.settings:#if a starting set of objects the robot knows about self_obstacles ['TARGET_A','TARGET_B']
            self.CE[plan].set_obstacles(self.settings['self_obstacles'])

            if 'dangers' in self.settings:#if a starting set of dangers the robot knows about
                #currently dangers just exist in the CE
                self.CE[plan].set_dangers(self.settings['dangers'])#at experiment start the robot assumes humans are ignorant of all dangers so only adds them to its own map
            
            self.CE[plan].set_speed_threshold(self.settings['speed_threshold'])



        self.travelled_path = []

        
        self.human_knowledge = {}
        for human in self.settings['humans']:
            self.human_knowledge[human] = []
            self.human_knowledge[human].append(self.settings[human + '_obstacles'])#initialise list of human knowledge, appended cos knowldge is an array of hypotheses of human knowledge
            #for obstacle in self.human_knowledge[human][0]:#for each obstacle
             #   obstacle.extend([0,1])#add percieved danger and confidence values to the end of the array set at initial default values
            
        #this initial knowledge setting could be modified to instead be estimated from facts about the world, e.g., things in human 'sensor' range    
        self.robot.speed_factor = self.settings['ROBOT_speed_factor]
        self.robot.update_background_checks(0, False)
        self.robot.update_background_checks(2, False)
        self.robot.go_to_position(self.settings['ROBOT_start'][0], self.settings('ROBOT_start')[1], blocking=True)
        self.robot.go_to_orientation(self.settings['ROBOT_start_angle'], blocking=True)
        
        self.Experiment_Logger.write('Running script: ' + self.settings['script_file'])
        
        self.CE_process = {}
        for plan in plan_types:
            self.CE_process[plan] = mp.Process(target=self.CE_process, args=(plan,))
            #self.CE_process[plan].start()
        self.results_q = mp.JoinableQueue()
        self.CE_manager = mp.Process(target=self.CE_manager)
        self.end_flag = False
        
    def CE_manager(self):
        #continually grab the output from the plan processes
        #when all 3 plans have sent a message allow them all to do more processing
        #compare results and selct and execute plan
        #check for experiment end conditions to break out of loop, and set end_flag so CE_processes end
        not_moving = {}
        warning_given = {}
        for human in self.settings['humans']:
            not_moving[human] = 0
            warning_given[human] = False
        msgs = 0
        for sim_steps in range(1000):
            consequence_results = {}
            while msgs < 3:#keep grabbing msgs until 3 have been grabbed - one from each CE
                result = self.results_q.get()
                consequence_results[result['plan']] = result#store the 3 results in a dictionary keyed by plan type
                msgs = msgs_counter + 1
            #all 3 msgs received so process them
            #the returned results will contain the evaluation score and the plan
            #the scores get compared and the best plan is stored in plan so it can be executed
                
            current_position = self.tracker.get_position(self.name)[0:2]
            self.travelled_path.append(current_position)
            
            distance_to_target = (numpy.sum((current_position - plan['position'])**2))**0.5
            if distance_to_target > 0.5:
                robot_motion = self.CE[plan['type']].motion_command(plan['position'], plan, plot=planned_path_robot)
                next_position_robot = robot_motion['next_position']
                self.robot.go_to_position(next_position_robot[0], next_position_robot[1])
            elif abs(self.tracker.get_rotation()-plan['angle'])>0.1:#if at target and not at correct angle
                self.robot.go_to_orientation(plan['angle'])#rotate
            else:
                #if move and warn selected
                if plan == 'warn':
                    #if not at warn location: plan path and move
                    self.robot.speak_text(self.settings['warning_call'], blocking=True)
                    self.robot_q.put({'warning_type' : 'warn'})
                    self.robot_q.put({'warning_type' : 'warn'})
                    warning_given[human] = True
                    #self.robot_q.put(warn_msg)#warn_msg dict and contents need defining
                #if move and point selected:
                if plan == 'point':
                    #if not at point location: plan path and move
                    #else: give point, post point message to queue and wait for ack
                    #self.robot_q.put(point_msg)#point_msg dict and contents need defining  
                    self.robot.point_direction_world(point_params['point_pos'][0], point_params['point_pos'][1])
                    self.robot_q.put({'warning_type' : 'point'})
                    self.robot_q.put({'warning_type' : 'point'})
                    warning_given[human] = True

            if True in warning_given.values:
                while not self.human_q.empty():
                     msg = self.human_q.get()
                     self.human_knowledge[msg['name']][hypothesis_selected[msg['name']]].extend(self.CE[plan].infer_actor_goal(msg['name'], minimal_return=True))
                     warning_given[msg['name']] = False

            for human in self.settings['humans']:#for each human in the experiment
                if self.tracker.get_speed(human) < self.settings['speed_threshold']:#check human velocity 
                    not_moving[human] = not_moving[human] + 1

            if all(i>3 for i in not_moving.values()): 
                self.end_flag = True#cause CE_processes to terminate on next loop
                msgs = 0
                for _ in range(3):
                    self.results_q.task_done()#let the CE processes enter their next loop where the end flag will be checked
                break#CE thread will run until all robots are stationary or 1000 iteration steps
            
            msgs = 0
            for _ in range(3):
                self.results_q.task_done()#let the CE processes start on producing the next msg set
            
        
    def CE_process(self, plan):
        not_moving = {}
        warning_given = {}
        for human in self.settings['humans']:
            not_moving[human] = 0
            warning_given[human] = False
        #TODO load a GP, which GP to load is dependent on the plan type and the situation parameters
        while not self.end_flag:
            #run the CE
            #set the parameters for the plan. This should be done using the ML framework, to generate values to test, 
            #the following plan evaluation will be called multiple times to use baysian optimisation for the plan class, and the optimised plan passed as a message to the CE_manager process
            #
            plan_params = {'angle': 0, 'position': [0,0], 'point_pos' : [0,0], 'speed': 0.5}#point needs an extra parameter for the place to point to
            

            #calculate the scores for each hypothesis for each human, and store them in a dictionary
            consequence_results = {}
            hypothesis_selected = {}
            for human in self.settings['humans']:#for each human in the experiment
                for hypothesis in enumerate(self.human_knowledge[human]):#for all hypotheses of what that human knows about
                    #compare human actions with what they would be doing according to each hypothesis and score them according to how likely they are
                    #plan path for a human from the start position to the assumed target with the assumed obstacle list and compare with actual path taken
                    #get confidence scores for each hypothesis, deleting hypotheses if they are below a threshold
                    #select hypothesis for each human
                    pass
                hypothesis_selected[human] = 0#no hypothesis checking yet so just choose the first one
                human_speed = self.settings[human + '_speed_factor']
                
                if(plan_params[speed]<human_speed)#if the robot will be slower
                    self.CE[plan].change_step(human,0.25)#set the human to the default step size as it is faster
                    step = 0.25 * (plan_params[plan][speed]/human_speed)#calculate smaller step size
                    self.CE[plan].change_step('ROBOT',step)#reduce the step size for the robot
                elif(plan_params[plan][speed]>human_speed)#if the robot will be faster
                    self.CE[plan].change_step('ROBOT',plan,0.25)#set the human to the default step size as it is faster
                    step = 0.25 * (human_speed/plan_params[plan][speed])#calculate smaller step size
                    self.CE[plan].change_step(human,step)#reduce the step size for the robot                self.CE.set_obstacles(self.human_knowledge[human][hypothesis_selected[human]], actor=human)#create graph of current human world view in the CE
                consequence_results[human] = self.CE[plan].predict_all(human, plan_params, plot=self.settings['do_plotting'], template=self.settings['plot_template'])#need to modify the CE call to pass it the parameters of the plan

            output_msg = {}

            #copy the plan parameters into the output msg
            output_msg['type'] = plan
            for key,value in plan_params.iteritems():
                output_msg[key] = value

            for key in consequence_results['HUMAN_A'].keys():
                output_msg[key] = 0

            for consequence_result in consequence_results.values():
                for key,value in consequence_result.iteritems():
                    #add the results together somehow - if it is just a single numerical score that's easy. I might want to look at separate score factors that need combining individually and weigthing
                    output_msg[key] = output_msg[key] + value
                    #add the scores to the GP model(s) and evaluate if further optimisation needed
                    #compare the 3 scores to see which plan to select
            self.results_q.put(output_msg)#put the output msg into the q
            self.results_q.join()#wait until the msgs from all 3 CEs are processed and a new one so notified to proceed
                    
                
                
